{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install paddlepaddle==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics==8.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo YOLOV8 para classificação de imagens\n",
    "model = YOLO('../src/runs/classify/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo PaddleOCR para OCR\n",
    "ocr = PaddleOCR(lang=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializa a webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Captura um frame da webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Detecta objetos no frame usando YOLOv8\n",
    "    detections = model.detect(frame)\n",
    "\n",
    "    # Itera sobre as detecções\n",
    "    for detection in detections:\n",
    "        # Verifica se o objeto é um documento de texto\n",
    "        if detection.class_name == \"document\":\n",
    "            # Realiza OCR no documento usando o PaddleOCR\n",
    "            result = ocr.ocr(detection.image)\n",
    "\n",
    "            # Imprime o texto reconhecido\n",
    "            print(result[0][1])\n",
    "        else:\n",
    "            # Descreve a cena usando o modelo pre-treinado para imagens naturais\n",
    "            caption = model.describe_image(detection.image)\n",
    "            print(caption)\n",
    "\n",
    "    # Exibe o frame\n",
    "    cv2.imshow(\"Imagem\", frame)\n",
    "\n",
    "    # Verifica se o usuário pressionou a tecla 'q' para sair\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Libera a webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import paddleocr\n",
    "\n",
    "# Define os parâmetros de treinamento\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "# Carrega o dataset de imagens naturais\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    \"dataset/train\",\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Cria o modelo de descrição de cena\n",
    "model = paddleocr.SceneDescriptionModel()\n",
    "\n",
    "# Define a função de perda\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define o otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Treina o modelo\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Obtém as entradas e rótulos\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Ativa o modo de treinamento\n",
    "        model.train()\n",
    "\n",
    "        # Realiza um passo de forward propagation\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calcula a perda\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Realiza um backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os pesos\n",
    "        optimizer.step()\n",
    "\n",
    "        # Imprime o progresso do treinamento\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "# Salva o modelo treinado\n",
    "torch.save(model.state_dict(), \"scene_description_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
